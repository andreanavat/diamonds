{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import ksone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "import re\n",
    "from joblib import dump, load\n",
    "import joblib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diamonds.csv')\n",
    "df_coords = pd.read_csv('coords_diamonds.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df.columns:\n",
    "#     print(x)\n",
    "#     # Configurar el gráfico\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.lineplot(data=df[x], palette='BuPu')  # Seaborn usará el índice para el eje X\n",
    "\n",
    "\n",
    "\n",
    "#     # Mostrar el gráfico\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homologación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar los valores\n",
    "def limpiar_valor(valor):\n",
    "    # Eliminar caracteres especiales\n",
    "    valor_limpio = re.sub(r\"[^a-zA-Z\\s]\", '', valor)\n",
    "    # Corregir errores comunes y homologar\n",
    "    correcciones = {\n",
    "        'Very Goo': 'Very Good',\n",
    "        'Very Go': 'Very Good',\n",
    "        'V&ery Good': 'Very Good',\n",
    "        'Very G#ood': 'Very Good',\n",
    "        \"Very *'Good\": 'Very Good',\n",
    "        'Very Go#od': 'Very Good',\n",
    "        'Ide&al': 'Ideal',\n",
    "        'Ide!al': 'Ideal',\n",
    "        'Id!eal': 'Ideal',\n",
    "        \"Ide*'al\": 'Ideal',\n",
    "        '*Ideal': 'Ideal',\n",
    "        'I#deal': 'Ideal',\n",
    "        '&Ideal': 'Ideal',\n",
    "        'Pre!mium': 'Premium',\n",
    "        'Pr?emium': 'Premium',\n",
    "        \"P*'remium\": 'Premium',\n",
    "        'P?remium': 'Premium',\n",
    "        '&Premium': 'Premium',\n",
    "        'Go?od': 'Good',\n",
    "        'G#ood': 'Good',\n",
    "        '!Good': 'Good'\n",
    "    }\n",
    "    return correcciones.get(valor_limpio, valor_limpio)\n",
    "\n",
    "# Limpiar y homologar los valores de la columna\n",
    "df['cut'] = df['cut'].apply(limpiar_valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['color'] = df['color'].replace(to_replace=r\"[^EIJHFGD]\", value='', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo = {\n",
    "    'SI2': 'SI2', 'SI1': 'SI1', 'VS1': 'VS1', 'VS2': 'VS2', 'VVS2': 'VVS2', 'VVS1': 'VVS1',\n",
    "    'I1': 'I1', 'IF': 'IF',\n",
    "    'S?I1': 'SI1', 'SI!1': 'SI1', '&VS2': 'VS2', '&SI2': 'SI2', \"S*'I1\": 'SI1',\n",
    "    'VS?1': 'VS1', \"S*'I2\": 'SI2', '#VS1': 'VS1', 'V&S2': 'VS2', 'V!S2': 'VS2',\n",
    "    '!VS2': 'VS2', 'VS#2': 'VS2', \"VVS*'2\": 'VVS2', \"*'SI2\": 'SI2', 'VV?S1': 'VVS1',\n",
    "    'S&I1': 'SI1', \"*'SI1\": 'SI1', 'SI?1': 'SI1', 'VV#S1': 'VVS1', 'V#S2': 'VS2',\n",
    "    '#SI!1': 'SI1', 'S!I2': 'SI2'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar la función replace con regex=True para habilitar expresiones regulares\n",
    "df['clarity'] = df['clarity'].replace(mapeo, regex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columnas númericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n"
     ]
    }
   ],
   "source": [
    "num_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "def validate_num_columns(df, num_columns):\n",
    "    for column in num_columns:\n",
    "        tipo_dato = df[column].dtypes\n",
    "\n",
    "        # Verificar si el tipo de dato es numérico\n",
    "        if tipo_dato == 'int' or tipo_dato == 'float':\n",
    "            print(\"La columna es completamente numérica\")\n",
    "        else:\n",
    "            print(f\"La columna {column} tiene datos no numéricos\")\n",
    "validate_num_columns(df,num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columnas de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna es completamente texto\n",
      "La columna es completamente texto\n",
      "La columna es completamente texto\n"
     ]
    }
   ],
   "source": [
    "num_columns = df.select_dtypes(include=['object']).columns\n",
    "def categorical_column(df, num_columns):\n",
    "    for column in num_columns:\n",
    "        tipo_dato = df[column].dtypes\n",
    "\n",
    "        # Verificar si el tipo de dato es numérico\n",
    "        if tipo_dato == 'object' or tipo_dato == 'object':\n",
    "            print(\"La columna es completamente texto\")\n",
    "        else:\n",
    "            print(f\"La columna {column} tiene datos no texto\")\n",
    "\n",
    "categorical_column(df, num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missings values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestros conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test=train_test_split(df,test_size=.2,random_state=413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df,num_columns):\n",
    "    for column in num_columns:\n",
    "        mean = df[column].dropna().mean()\n",
    "        median = df[column].dropna().median()\n",
    "        mode = df[column].dropna().mode()[0]  # mode() devuelve una Serie, toma el primer valor\n",
    "        \n",
    "        print(f\"\\n{column}: La media es {mean}, la mediana es {median}, y el modo es {mode}\")\n",
    "        \n",
    "        for metric in [mean, median, mode]:\n",
    "            originales = list(df[column].dropna().values)\n",
    "            imputados = list(df[column].fillna(metric).values)\n",
    "            \n",
    "            # Ejecutar la prueba KS\n",
    "            ks_stat, ks_pvalue = stats.ks_2samp(originales, imputados)\n",
    "            \n",
    "            # Imprimir o almacenar los resultados\n",
    "            print(f\"Prueba KS para {metric}: estadístico={ks_stat}, p-valor={ks_pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "depth: La media es 61.7516227951819, la mediana es 61.8, y el modo es 62.0\n",
      "Prueba KS para 61.7516227951819: estadístico=0.029593963871762496, p-valor=2.2130365911915135e-16\n",
      "Prueba KS para 61.8: estadístico=0.02748194668708115, p-valor=3.4751680220647744e-14\n",
      "Prueba KS para 62.0: estadístico=0.029883689306071326, p-valor=1.0741422552910769e-16\n",
      "\n",
      "x: La media es 5.728688699108136, la mediana es 5.69, y el modo es 4.37\n",
      "Prueba KS para 5.728688699108136: estadístico=0.01039515926092327, p-valor=0.01967489540692731\n",
      "Prueba KS para 5.69: estadístico=0.010113691511548506, p-valor=0.025180008502440954\n",
      "Prueba KS para 4.37: estadístico=0.01789234955124283, p-valor=2.2814308079606564e-06\n",
      "\n",
      "y: La media es 5.731230639454507, la mediana es 5.71, y el modo es 4.33\n",
      "Prueba KS para 5.731230639454507: estadístico=0.005548181400352514, p-valor=0.5218516493109235\n",
      "Prueba KS para 5.71: estadístico=0.005405387063054268, p-valor=0.555752257300214\n",
      "Prueba KS para 4.33: estadístico=0.009979117586142616, p-valor=0.02769077043159418\n"
     ]
    }
   ],
   "source": [
    "num_columns = df.columns[df.isna().any()].tolist()\n",
    "missing_values(X_train,num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor valor a imputar:\n",
    "- Para \"depth\", se recomienda la mediana.\n",
    "- Para \"x\", se recomienda la mediana, aunque la diferencia con la media es mínima.\n",
    "- Para \"y\", se recomienda la mediana, dada su semejanza más cercana con la distribución original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2449036/3201589919.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[column]=imp.fit_transform(X_train[[column]])\n",
      "/tmp/ipykernel_2449036/3201589919.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[column]=imp.transform(X_test[[column]])\n",
      "/tmp/ipykernel_2449036/3201589919.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[column]=imp.fit_transform(X_train[[column]])\n",
      "/tmp/ipykernel_2449036/3201589919.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[column]=imp.transform(X_test[[column]])\n",
      "/tmp/ipykernel_2449036/3201589919.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[column]=imp.fit_transform(X_train[[column]])\n",
      "/tmp/ipykernel_2449036/3201589919.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[column]=imp.transform(X_test[[column]])\n"
     ]
    }
   ],
   "source": [
    "def complete_missing_values(imp,num_columns):\n",
    "    for column in num_columns:\n",
    "        X_train[column]=imp.fit_transform(X_train[[column]])\n",
    "        X_test[column]=imp.transform(X_test[[column]])\n",
    "\n",
    "imp=SimpleImputer(missing_values=np.nan,strategy=\"median\")\n",
    "complete_missing_values(imp,num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unificamos en df limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators: número de árboles que forman el modelo.\n",
    "\n",
    "- max_samples: número de observaciones empleadas para entrenar cada árbol.\n",
    "\n",
    "- max_features : El número de características que se extraerán para entrenar cada estimador base.\n",
    "\n",
    "- contamination: proporción de anomalías esperadas en los datos de entrenamiento. En base a este valor, se establece el límite acorde al cual se clasifican las observaciones en normales o anómalas.\n",
    "\n",
    "- random_state: semilla para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "Se procede a entrenar un modelo asumiendo que hay un 1% de observaciones anómalas en el conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2449036/779421519.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_iso[\"outlier\"]=model.predict(df_iso)\n"
     ]
    }
   ],
   "source": [
    "df_iso = df.select_dtypes(include=['int64', 'float64'])\n",
    "max_features=df_iso.shape[1]\n",
    "n_estimators=50\n",
    "max_samples='auto'\n",
    "contamination=float(0.06)\n",
    "model=IsolationForest(max_features = max_features, n_estimators=n_estimators, max_samples=max_samples, contamination=contamination)\n",
    "model.fit(df_iso)\n",
    "df_iso[\"outlier\"]=model.predict(df_iso)\n",
    "df = pd.concat([df_iso, df[['cut', 'color', 'clarity']]], axis=1)\n",
    "df = df[df[\"outlier\"]!=-1].reset_index(drop=True)\n",
    "df = df.drop('outlier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    50694\n",
       "-1     3236\n",
       "Name: outlier, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iso.outlier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    50694\n",
       "-1     3236\n",
       "Name: outlier, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iso.outlier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    50694\n",
       "-1     3236\n",
       "Name: outlier, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iso.outlier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df.columns:\n",
    "#     print(x)\n",
    "#     # Configurar el gráfico\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.lineplot(data=df[x], palette='BuPu')  # Seaborn usará el índice para el eje X\n",
    "\n",
    "\n",
    "\n",
    "#     # Mostrar el gráfico\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df,columns = num_columns, prefix_sep='_') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df):\n",
    "    corr=df.corr(method=\"spearman\")\n",
    "    corr=abs(corr)\n",
    "    corr=corr[['price']].sort_values(by = 'price' , ascending = False)\n",
    "    list_corr = list(corr[corr['price']>.01].index)\n",
    "    df = df[list_corr]\n",
    "    return df, list_corr\n",
    "\n",
    "df, list_corr = correlation(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_scaler.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precio_scaler = MinMaxScaler()\n",
    "precio_scaler.fit(df[['price']])\n",
    "joblib.dump(precio_scaler, 'price_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    X_train,X_test=train_test_split(df,test_size=.2,random_state=413)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    index_train = X_train.index\n",
    "    index_test = X_test.index\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=index_test)\n",
    "    X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=index_train)\n",
    "    df = pd.concat([X_train, X_test], axis=0)\n",
    "    return df\n",
    "\n",
    "df = normalize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características y la variable objetivo\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predecir en el conjunto de entrenamiento y en el conjunto de prueba\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluar el modelo para el conjunto de entrenamiento y prueba\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : MSE = 0.002812, R^2 = 0.91\n",
      "Test: MSE = 0.002718, R^2 = 0.91\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train : MSE = {mse_train:.6f}, R^2 = {r2_train:.2f}\")\n",
    "print(f\"Test: MSE = {mse_test:.6f}, R^2 = {r2_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El modelo no está sobreajustado de manera significativa, ya que no hay una gran diferencia entre el MSE del conjunto de entrenamiento y el de prueba, lo que sugiere que el modelo tiene un rendimiento consistente en ambos conjuntos.\n",
    "\n",
    " Los resultados del Score es un indicativo de un buen ajuste y de una buena capacidad de generalización del modelo. Lo que significa que el modelo puede explicar el 90% de la variabilidad en los precios de los diamantes, lo cual son excelentes resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en el conjunto de entrenamiento: MSE = 0.002129, R^2 = 0.93\n",
      "Rendimiento en el conjunto de prueba: MSE = 0.002139, R^2 = 0.93\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Inicializar y entrenar el modelo SVR\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de entrenamiento y en el conjunto de prueba\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "# Evaluar el modelo para el conjunto de entrenamiento\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Evaluar el modelo para el conjunto de prueba\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Rendimiento en el conjunto de entrenamiento: MSE = {mse_train:.6f}, R^2 = {r2_train:.2f}\")\n",
    "print(f\"Rendimiento en el conjunto de prueba: MSE = {mse_test:.6f}, R^2 = {r2_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el modelo de regresión lineal como el modelo de Máquinas de Soporte Vectorial (SVM) han demostrado ajustarse bastante bien a nuestros datos.\n",
    "Podemos concluir que estamos bien posicionados para proporcionar estimaciones de precios de diamantes confiables y precisas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much are stolen diamonds worth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos la versión final del modelo que usaremos para nuestras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stolendiamonds = pd.read_csv('StolenDiamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "# # Guardar el modelo a un archivo\n",
    "# dump(model, 'model_regresion_lineal.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, list_corr, num_columns_numeric, num_columns_categoric):\n",
    "    df['cut'] = df['cut'].apply(limpiar_valor)\n",
    "    df['color'] = df['color'].replace(to_replace=r\"[^EIJHFGD]\", value='', regex=True)\n",
    "    df['clarity'] = df['clarity'].replace(mapeo, regex=False)\n",
    "    validate_num_columns(df, num_columns_numeric)\n",
    "    categorical_column(df, num_columns_categoric)\n",
    "    df = pd.get_dummies(df, columns=num_columns_categoric, prefix_sep='_')  \n",
    "    \n",
    "    for column in list_corr:\n",
    "        if column not in df.columns:\n",
    "            df[column] = 0  # Crea la columna y asigna el valor '0'\n",
    "    \n",
    "    df = df[list_corr]  # Se asegura de que df solo contenga las columnas en list_corr\n",
    "    df = normalize(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stolendiamonds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente numérica\n",
      "La columna es completamente texto\n",
      "La columna es completamente texto\n",
      "La columna es completamente texto\n"
     ]
    }
   ],
   "source": [
    "num_columns_numeric = stolendiamonds.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_columns_categoric = stolendiamonds.select_dtypes(include=['object']).columns\n",
    "list_corr = ['carat', 'y', 'z', 'x', 'table', 'clarity_SI2', 'clarity_VVS1',\n",
    " 'cut_Ideal', 'cut_Premium', 'color_E', 'clarity_IF', 'clarity_VVS2', 'color_J',\n",
    " 'color_D', 'cut_Fair', 'color_H', 'clarity_SI1', 'color_I', 'depth',\n",
    " 'cut_Good', 'clarity_I1', 'cut_Very Good', 'clarity_VS1', 'color_G']\n",
    "df_preprocessed = preprocessing(stolendiamonds, list_corr, num_columns_numeric, num_columns_categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = load('model_regresion_lineal.joblib')\n",
    "precio_scaler_loaded = joblib.load('price_scaler.joblib')\n",
    "\n",
    "# Hacer predicciones con el modelo\n",
    "y_pred = model_loaded.predict(df_preprocessed)\n",
    "\n",
    "# Realizar la transformación inversa de las predicciones de 'precio'\n",
    "y_pred_inverse = precio_scaler_loaded.inverse_transform(y_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price of stolen diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11454.21761658],\n",
       "       [ 4686.66986356],\n",
       "       [13085.49842229],\n",
       "       [  945.6321092 ],\n",
       "       [ 4118.38291106],\n",
       "       [ 9870.29362177],\n",
       "       [10215.38293269],\n",
       "       [ 3358.51625878],\n",
       "       [15260.520776  ],\n",
       "       [10835.30156777]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qstyle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
